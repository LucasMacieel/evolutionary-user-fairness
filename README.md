# User-oriented Fairness in Recommendation

This repository includes the implementation for User-oriented Fairness in Recommendation, based on:

*Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2021. User-oriented Fairness in Recommendation. In Proceedings of the Web Conference 2021 (WWW'21).*

## Features

This implementation extends the original work with:

- **MILP Solver** (`model.py`): Mixed Integer Linear Programming solver using PuLP with HiGHS/SCIP backends
- **Genetic Algorithm Optimizer** (`ga_optimizer.py`): Vectorized GA with:
  - Adaptive penalty mechanism (Bean & Hadj-Alouane method)
  - Non-uniform mutation decay
  - Multi-parent crossover
  - Tournament selection with Deb's feasibility rules
  - Disk caching for vectorized data
- **Hyperparameter Tuning** (`ga_hyperparameter_tuning.py`): Optuna-based TPE optimization
- **Statistical Evaluation** (`ga_statistical_evaluation.py`): Multi-run statistical analysis (30 runs by default)
- **Visualization** (`plotter.py`): Result plotting utilities

## Reference

```bibtex
@inproceedings{li2021user,
  title={User-oriented Fairness in Recommendation},
  author={Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang},
  booktitle={Proceedings of the the Web Conference 2021},
  year={2021}
}
```

## Requirements

Python 3.8+

Install dependencies:
```bash
pip install -r requirements.txt
```

Dependencies:
- `numpy` - Vectorized computations
- `pandas` - Data manipulation
- `pulp` - MILP optimization (HiGHS solver included)
- `matplotlib`, `seaborn` - Visualization
- `optuna` - Hyperparameter optimization (for tuning module)

## Datasets

- The processed datasets are in [`./dataset/`](./dataset/)
- **Amazon Datasets**: The origin dataset can be found [here](http://jmcauley.ucsd.edu/data/amazon/)
- For each dataset directory contains processed splitted testing datasets for re-ranking:
  - `0.05_count_*_test_ratings.txt`: grouping by total number of interactions
  - `sum_0.05_price_*_test_ratings.txt`: grouping by total consumption
  - `max_0.05_price_*_test_ratings.txt`: grouping by maximum price
- Sample rank files generated by NCF and biasedMF are provided under each dataset directory. Please decompress each `.tar.gz` file before running.

## Usage

### Prepare Input Data

Put the ranking file generated by your recommendation model under the corresponding dataset folder. For example, to run with 5Beauty-rand dataset, put the `*_rank.csv` file under `dataset/5Beauty-rand/` directory.

Ranking CSV file format: `uid \t iid \t score \t label`
- `uid`: user id
- `iid`: item id  
- `score`: predicted score
- `label`: 0 or 1 (negative or positive sample)

### MILP Solver

Run the Mixed Integer Linear Programming solver:

```bash
cd src/
python model.py
```

Configure in `model.py`:
- `dataset_name`, `model_name`, `group_name_title`
- `epsilon`: Fairness constraint threshold (use `"auto"` for dynamic calculation)
- `solver`: Choose between `"highs"` or `"scip"`

### Genetic Algorithm Optimizer

Run the GA optimizer:

```bash
cd src/
python ga_optimizer.py
```

Key parameters:
- `population_size`: Population size (default: 50)
- `generations`: Number of generations (default: 100)
- `mutation_rate_max/min`: Adaptive mutation rate range
- `epsilon`: Fairness constraint (use `"auto"` for dynamic calculation)

### Hyperparameter Tuning

Run automated hyperparameter optimization using Optuna:

```bash
cd src/
python ga_hyperparameter_tuning.py --dataset 5Beauty-rand --model biasedMF --group count --n-trials 50
```

Options:
- `--dataset`: Dataset name
- `--model`: Model name (biasedMF, NCF)
- `--group`: Grouping method (count, max_price, sum_price)
- `--n-trials`: Number of optimization trials
- `--timeout`: Maximum time in seconds

### Statistical Evaluation

Run multiple GA iterations for statistical analysis:

```bash
cd src/
python ga_statistical_evaluation.py --n-runs 30
```

Options:
- `--n-runs`: Number of runs per configuration (default: 30)
- `--datasets`: Specific datasets to evaluate
- `--models`: Specific models to evaluate

Results include mean, std, median, 95% CI, IQR, and success rate for all metrics.

## Results

Results are saved in `./results/` with subdirectories:
- `highs/`, `scip/`: MILP solver outputs
- `ga/`, `newGA/`: GA optimizer outputs
- `tuning/`: Hyperparameter tuning results
- `statistical/`: Statistical evaluation results

## Project Structure

```
user-fairness/
├── dataset/                    # Processed datasets
├── results/                    # Output results
├── src/
│   ├── model.py               # MILP solver (PuLP/HiGHS/SCIP)
│   ├── ga_optimizer.py        # Genetic Algorithm optimizer
│   ├── ga_hyperparameter_tuning.py  # Optuna hyperparameter tuning
│   ├── ga_statistical_evaluation.py # Statistical evaluation module
│   ├── data_loader.py         # Data loading utilities
│   ├── plotter.py             # Visualization utilities
│   ├── cache/                 # Vectorized data cache
│   └── utils/
│       └── tools.py           # Helper functions
├── requirements.txt
└── README.md
```

## License

This project is for research purposes. Please cite the original paper if you use this code.
